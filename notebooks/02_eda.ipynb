{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83dd482",
   "metadata": {},
   "source": [
    "# This notebook is for what we used in Kaggle to replicate the repo and run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c449d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b15e4",
   "metadata": {},
   "source": [
    "## Cloning repo from GitHub into Kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907a42c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/jonny0349/kaggle-sci-image-forgery-seg.git /kaggle/working/kaggle-sci-image-forgery-seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae4c9e",
   "metadata": {},
   "source": [
    "## Installing ONLY non-torch deps to avoid breaking CUDA torch\n",
    "\n",
    "This prevents the \"CUDA available False\" + torch wheel mess we were having before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2ef14",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U --no-cache-dir \\\n",
    "    segmentation-models-pytorch \\\n",
    "    albumentations \\\n",
    "    timm \\\n",
    "    ruamel.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbc762",
   "metadata": {},
   "source": [
    "## Create Kaggle config from baseline and patch paths + GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30feb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruamel.yaml import YAML\n",
    "from pathlib import Path\n",
    "\n",
    "REPO = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg\")\n",
    "BASE = REPO / \"configs\" / \"baseline.yaml\"\n",
    "KCFG = REPO / \"configs\" / \"kaggle.yaml\"\n",
    "\n",
    "DATASET_ROOT = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection\"\n",
    "\n",
    "#Copy baseline -> Kaggle\n",
    "KCFG.write_text(BASE.read_text())\n",
    "\n",
    "yaml = YAML()\n",
    "with KCFG.open(\"r\") as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "#Core kaggle changes\n",
    "cfg[\"project\"][\"device\"] = \"cuda\"\n",
    "cfg[\"data\"][\"root\"] = DATASET_ROOT\n",
    "\n",
    "#Outputs must be writable on Kaggle\n",
    "if \"outputs\" in cfg and isinstance(cfg[\"outputs\"], dict) and \"root\" in cfg[\"outputs\"]:\n",
    "    cfg[\"outputs\"][\"root\"] = \"/kaggle/working/outputs\"\n",
    "\n",
    "#Reasonable first real run on a T4\n",
    "cfg[\"train\"][\"epochs\"] = 10\n",
    "cfg[\"train\"][\"batch_size\"] = 8\n",
    "cfg[\"train\"][\"num_workers\"] = 2\n",
    "cfg[\"val\"][\"interval_epochs\"] = 1\n",
    "\n",
    "with KCFG.open(\"w\") as f:\n",
    "    yaml.dump(cfg, f)\n",
    "\n",
    "print(\"Wrote:\", KCFG)\n",
    "print(\"data.root =\", cfg[\"data\"][\"root\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d34b28",
   "metadata": {},
   "source": [
    "## Patch train.py to avoid TensorBoard crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/train.py\")\n",
    "s = p.read_text()\n",
    "\n",
    "# 1) Ensure the SummaryWriter import is wrapped safely\n",
    "s = re.sub(\n",
    "    r\"^\\s*from torch\\.utils\\.tensorboard import SummaryWriter.*$\",\n",
    "    \"try:\\n    from torch.utils.tensorboard import SummaryWriter  # type: ignore\\nexcept Exception:\\n    SummaryWriter = None\",\n",
    "    s,\n",
    "    flags=re.MULTILINE\n",
    ")\n",
    "\n",
    "# 2) Replace writer creation with a safe conditional\n",
    "# Common pattern in your file: writer = SummaryWriter(log_dir=paths[\"logs\"])\n",
    "s = s.replace(\n",
    "    'writer = SummaryWriter(log_dir=paths[\"logs\"])',\n",
    "    'writer = SummaryWriter(log_dir=paths[\"logs\"]) if SummaryWriter is not None else None'\n",
    ")\n",
    "\n",
    "# 3) Guard add_scalar calls (only if not already guarded)\n",
    "# This will wrap any bare \"writer.add_scalar(\" lines.\n",
    "lines = s.splitlines()\n",
    "out = []\n",
    "for line in lines:\n",
    "    if \"writer.add_scalar(\" in line and \"if writer is not None\" not in line:\n",
    "        indent = re.match(r\"^(\\s*)\", line).group(1)\n",
    "        out.append(f\"{indent}if writer is not None:\")\n",
    "        out.append(f\"{indent}    {line.strip()}\")\n",
    "    else:\n",
    "        out.append(line)\n",
    "s2 = \"\\n\".join(out)\n",
    "\n",
    "p.write_text(s2)\n",
    "print(\"Patched train.py: SummaryWriter now truly optional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/train.py\")\n",
    "s = p.read_text()\n",
    "\n",
    "# 1) Remove/neutralize the TensorBoard import (no try/except at all)\n",
    "s = re.sub(\n",
    "    r\"^\\s*from torch\\.utils\\.tensorboard import SummaryWriter.*$\",\n",
    "    \"SummaryWriter = None  # TensorBoard disabled on Kaggle (protobuf/tensorboard mismatch)\",\n",
    "    s,\n",
    "    flags=re.MULTILINE\n",
    ")\n",
    "\n",
    "# 2) Force writer to None (handles the common exact line)\n",
    "s = s.replace(\n",
    "    'writer = SummaryWriter(log_dir=paths[\"logs\"])',\n",
    "    'writer = None  # TensorBoard disabled on Kaggle'\n",
    ")\n",
    "\n",
    "# 3) Comment out any writer.add_scalar lines\n",
    "s = re.sub(\n",
    "    r\"^(\\s*)writer\\.add_scalar\\(\",\n",
    "    r\"\\1# writer.add_scalar(\",\n",
    "    s,\n",
    "    flags=re.MULTILINE\n",
    ")\n",
    "\n",
    "p.write_text(s)\n",
    "print(\"TensorBoard disabled safely in train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b28f38",
   "metadata": {},
   "source": [
    "Patching YAML again to point to the right folders on the input data set. We were pointing to train_images: train/images but that folder does not exist. So we point to the right folder train_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruamel.yaml import YAML\n",
    "from pathlib import Path\n",
    "\n",
    "cfg_path = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/configs/kaggle.yaml\")\n",
    "yaml = YAML()\n",
    "with cfg_path.open(\"r\") as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "# Helper: set key if it exists\n",
    "def set_if_exists(d, key, val):\n",
    "    if isinstance(d, dict) and key in d:\n",
    "        d[key] = val\n",
    "\n",
    "# Common conventions across configs\n",
    "set_if_exists(cfg.get(\"data\", {}), \"train_images\", \"train_images\")\n",
    "set_if_exists(cfg.get(\"data\", {}), \"train_masks\", \"train_masks\")\n",
    "set_if_exists(cfg.get(\"data\", {}), \"val_images\", \"train_images\")   # temporary: reuse train as val if no val split\n",
    "set_if_exists(cfg.get(\"data\", {}), \"val_masks\", \"train_masks\")\n",
    "\n",
    "set_if_exists(cfg.get(\"train\", {}), \"images_dir\", \"train_images\")\n",
    "set_if_exists(cfg.get(\"train\", {}), \"masks_dir\", \"train_masks\")\n",
    "set_if_exists(cfg.get(\"val\", {}), \"images_dir\", \"train_images\")    # temporary\n",
    "set_if_exists(cfg.get(\"val\", {}), \"masks_dir\", \"train_masks\")\n",
    "\n",
    "with cfg_path.open(\"w\") as f:\n",
    "    yaml.dump(cfg, f)\n",
    "\n",
    "print(\"Patched kaggle.yaml to use train_images/train_masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee10c8b",
   "metadata": {},
   "source": [
    "Its still pointing to the wrong path, so we are patching data.py to see if that fixes the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "path = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/data.py\")\n",
    "txt = path.read_text()\n",
    "\n",
    "# Inject a small resolver helper after imports (only once)\n",
    "if \"_resolve_kaggle_dir\" not in txt:\n",
    "    insert_after = \"import os\"\n",
    "    resolver = \"\"\"\n",
    "def _resolve_kaggle_dir(p: str) -> str:\n",
    "    \\\"\\\"\\\"Return an existing directory path by trying Kaggle-specific fallbacks.\n",
    "    This keeps local configs working while adapting to Kaggle datasets that use\n",
    "    train_images/train_masks instead of train/images, etc.\n",
    "    \\\"\\\"\\\"\n",
    "    if p is None:\n",
    "        return p\n",
    "    p = str(p)\n",
    "\n",
    "    # If it already exists, we're done\n",
    "    if os.path.isdir(p):\n",
    "        return p\n",
    "\n",
    "    # Common Kaggle layout: train_images / train_masks at dataset root\n",
    "    candidates = [\n",
    "        p.replace(\"/train/images\", \"/train_images\"),\n",
    "        p.replace(\"/train/masks\",  \"/train_masks\"),\n",
    "        p.replace(\"/val/images\",   \"/train_images\"),\n",
    "        p.replace(\"/val/masks\",    \"/train_masks\"),\n",
    "        p.replace(\"train/images\",  \"train_images\"),\n",
    "        p.replace(\"train/masks\",   \"train_masks\"),\n",
    "        p.replace(\"val/images\",    \"train_images\"),\n",
    "        p.replace(\"val/masks\",     \"train_masks\"),\n",
    "    ]\n",
    "\n",
    "    for c in candidates:\n",
    "        if c != p and os.path.isdir(c):\n",
    "            return c\n",
    "\n",
    "    # last resort: try sibling folders under the same dataset root\n",
    "    root = p\n",
    "    for _ in range(4):\n",
    "        root = os.path.dirname(root)\n",
    "    for c in [os.path.join(root, \"train_images\"),\n",
    "              os.path.join(root, \"train_masks\"),\n",
    "              os.path.join(root, \"test_images\")]:\n",
    "        if os.path.isdir(c):\n",
    "            # if asked for images, return train_images; if asked for masks, train_masks\n",
    "            if p.endswith(\"images\") or \"images\" in p:\n",
    "                return os.path.join(root, \"train_images\") if os.path.isdir(os.path.join(root, \"train_images\")) else p\n",
    "            if p.endswith(\"masks\") or \"masks\" in p:\n",
    "                return os.path.join(root, \"train_masks\") if os.path.isdir(os.path.join(root, \"train_masks\")) else p\n",
    "\n",
    "    return p\n",
    "\"\"\"\n",
    "    txt = txt.replace(insert_after, insert_after + resolver)\n",
    "\n",
    "# Now ensure ImageMaskDataset.__init__ resolves dirs before collecting ids\n",
    "# We look for the start of __init__ and inject two lines after images_dir/masks_dir assignment.\n",
    "if \"self.images_dir = _resolve_kaggle_dir(self.images_dir)\" not in txt:\n",
    "    # Insert after the first time self.images_dir and self.masks_dir exist in __init__\n",
    "    txt = re.sub(\n",
    "        r\"(self\\.images_dir\\s*=\\s*.*\\n\\s*self\\.masks_dir\\s*=\\s*.*\\n)\",\n",
    "        r\"\\1        self.images_dir = _resolve_kaggle_dir(self.images_dir)\\n        self.masks_dir  = _resolve_kaggle_dir(self.masks_dir)\\n\",\n",
    "        txt,\n",
    "        count=1\n",
    "    )\n",
    "\n",
    "path.write_text(txt)\n",
    "print(\"Patched data.py with Kaggle folder fallback resolver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7cb7b6",
   "metadata": {},
   "source": [
    "That fixed it but we found another issue. Currently, our collect_ids cannot resolve paths for the image pairs if they are inside a different folder, which they currently are inside the recod.ai/LUC paths (train_images/authentic, train_images/forged). Since the algorithm is incapable of searching inside these folders, we get an error saying that we didn't find any pairs when trying to train. Due to this, we will force data.py to safely find pairs inside other folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8142d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/data.py\")\n",
    "lines = p.read_text().splitlines()\n",
    "\n",
    "# Find start of _collect_ids\n",
    "start = None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.lstrip().startswith(\"def _collect_ids(\"):\n",
    "        start = i\n",
    "        break\n",
    "if start is None:\n",
    "    raise RuntimeError(\"Could not find def _collect_ids(\")\n",
    "\n",
    "# Find end by indentation\n",
    "base_indent = len(lines[start]) - len(lines[start].lstrip())\n",
    "end = None\n",
    "for j in range(start + 1, len(lines)):\n",
    "    l = lines[j]\n",
    "    if not l.strip():\n",
    "        continue\n",
    "    indent_len = len(l) - len(l.lstrip())\n",
    "    if indent_len <= base_indent and (l.strip().startswith(\"def \") or l.lstrip().startswith(\"class \")):\n",
    "        end = j\n",
    "        break\n",
    "if end is None:\n",
    "    end = len(lines)\n",
    "\n",
    "indent = \" \" * base_indent\n",
    "\n",
    "new_fn = [\n",
    "f\"{indent}def _collect_ids(self) -> list[str]:\",\n",
    "f\"{indent}    \\\"\\\"\\\"Collect matching (image, mask) pairs.\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    Supports Kaggle layout where images are nested:\",\n",
    "f\"{indent}        train_images/authentic/<stem>.<ext>\",\n",
    "f\"{indent}        train_images/forged/<stem>.<ext>\",\n",
    "f\"{indent}    while masks are flat:\",\n",
    "f\"{indent}        train_masks/<stem>.npy\",\n",
    "f\"{indent}    \\\"\\\"\\\"\",\n",
    "f\"{indent}    import os\",\n",
    "f\"{indent}    from glob import glob\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    img_dir = self.images_dir\",\n",
    "f\"{indent}    msk_dir = self.masks_dir\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    if not os.path.isdir(img_dir):\",\n",
    "f\"{indent}        raise RuntimeError(f\\\"Images directory not found: {{img_dir}}\\\")\",\n",
    "f\"{indent}    if not os.path.isdir(msk_dir):\",\n",
    "f\"{indent}        raise RuntimeError(f\\\"Masks directory not found: {{msk_dir}}\\\")\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    exts = ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp')\",\n",
    "f\"{indent}    img_paths = []\",\n",
    "f\"{indent}    for ext in exts:\",\n",
    "f\"{indent}        img_paths.extend(glob(os.path.join(img_dir, '**', f'*{{ext}}'), recursive=True))\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    stem_to_img = {{}}\",\n",
    "f\"{indent}    for ip in sorted(img_paths):\",\n",
    "f\"{indent}        stem = os.path.splitext(os.path.basename(ip))[0]\",\n",
    "f\"{indent}        stem_to_img.setdefault(stem, ip)\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    mask_paths = glob(os.path.join(msk_dir, '*.npy'))\",\n",
    "f\"{indent}    stem_to_msk = {{os.path.splitext(os.path.basename(mp))[0]: mp for mp in mask_paths}}\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    ids = sorted(set(stem_to_img.keys()) & set(stem_to_msk.keys()))\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    if len(ids) == 0:\",\n",
    "f\"{indent}        raise RuntimeError(\",\n",
    "f\"{indent}            f\\\"No (image, mask) pairs found under {{img_dir}} and {{msk_dir}}.\\\\n\\\"\",\n",
    "f\"{indent}            f\\\"Found images: {{len(stem_to_img)}} (sample={{list(stem_to_img)[:10]}})\\\\n\\\"\",\n",
    "f\"{indent}            f\\\"Found masks : {{len(stem_to_msk)}} (sample={{list(stem_to_msk)[:10]}})\\\\n\\\"\",\n",
    "f\"{indent}            f\\\"Expected matching stems between images and masks.\\\"\",\n",
    "f\"{indent}        )\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    self._stem_to_img = stem_to_img\",\n",
    "f\"{indent}    self._stem_to_msk = stem_to_msk\",\n",
    "f\"{indent}    return ids\",\n",
    "]\n",
    "\n",
    "patched = lines[:start] + new_fn + lines[end:]\n",
    "p.write_text(\"\\n\".join(patched) + \"\\n\")\n",
    "\n",
    "print(f\"Patched _collect_ids() from line {start+1} to {end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e525f",
   "metadata": {},
   "source": [
    "Patching getitem as well to use resolved paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2863a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/data.py\")\n",
    "lines = p.read_text().splitlines()\n",
    "\n",
    "# Find the cv2.imread line\n",
    "target_idx = None\n",
    "for i, line in enumerate(lines):\n",
    "    if \"cv2.imread\" in line:\n",
    "        target_idx = i\n",
    "        break\n",
    "\n",
    "if target_idx is None:\n",
    "    raise RuntimeError(\"Could not find cv2.imread in data.py\")\n",
    "\n",
    "indent = \" \" * (len(lines[target_idx]) - len(lines[target_idx].lstrip()))\n",
    "\n",
    "inject = [\n",
    "    f\"{indent}# --- Kaggle nested layout support (force correct path right before read) ---\",\n",
    "    f\"{indent}stem = self.ids[idx]\",\n",
    "    f\"{indent}img_path = getattr(self, '_stem_to_img', {{}}).get(stem)\",\n",
    "    f\"{indent}if img_path is None:\",\n",
    "    f\"{indent}    from glob import glob\",\n",
    "    f\"{indent}    cands = glob(os.path.join(self.images_dir, '**', f'{{stem}}.*'), recursive=True)\",\n",
    "    f\"{indent}    img_path = cands[0] if cands else os.path.join(self.images_dir, f'{{stem}}.png')\",\n",
    "]\n",
    "\n",
    "lines2 = lines[:target_idx] + inject + lines[target_idx:]\n",
    "p.write_text(\"\\n\".join(lines2) + \"\\n\")\n",
    "\n",
    "print(\"Correctly injected nested image resolution (escaped f-strings)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa2fda",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09760949",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cd /kaggle/working/kaggle-sci-image-forgery-seg && python -m src.train --cfg configs/kaggle.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af78fa1",
   "metadata": {},
   "source": [
    "We are getting a crash at the end after we disabled TensorBoard(writer = None) but the script is still calling writer.close() unconditionally. We will patch src/train.py to finish cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba739c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/train.py\")\n",
    "s = p.read_text()\n",
    "\n",
    "# Replace writer.close() with a guarded close\n",
    "s = s.replace(\"writer.close()\", \"if writer is not None:\\n        writer.close()\")\n",
    "\n",
    "p.write_text(s)\n",
    "print(\"Patched writer.close() guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb12565",
   "metadata": {},
   "source": [
    "Running Inference on a small batch to check if the computer learned something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37c47a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cd /kaggle/working/kaggle-sci-image-forgery-seg && python -m src.infer \\\n",
    "  --cfg configs/kaggle.yaml \\\n",
    "  --checkpoint /kaggle/working/kaggle-sci-image-forgery-seg/outputs/checkpoints/best_dice.pt \\\n",
    "  --input_dir /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/forged \\\n",
    "  --output_dir /kaggle/working/outputs/preds/forged_demo \\\n",
    "  --thr 0.5 \\\n",
    "  --save_overlay"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
