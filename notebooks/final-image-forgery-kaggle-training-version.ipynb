{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703f4717",
   "metadata": {
    "papermill": {
     "duration": 0.003525,
     "end_time": "2025-12-18T16:33:17.822989",
     "exception": false,
     "start_time": "2025-12-18T16:33:17.819464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**GPU SANITY CHECK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e93e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:17.830242Z",
     "iopub.status.busy": "2025-12-18T16:33:17.829692Z",
     "iopub.status.idle": "2025-12-18T16:33:21.544410Z",
     "shell.execute_reply": "2025-12-18T16:33:21.543700Z"
    },
    "papermill": {
     "duration": 3.720476,
     "end_time": "2025-12-18T16:33:21.546273",
     "exception": false,
     "start_time": "2025-12-18T16:33:17.825797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "CWD: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026dab24",
   "metadata": {
    "papermill": {
     "duration": 0.002791,
     "end_time": "2025-12-18T16:33:21.551986",
     "exception": false,
     "start_time": "2025-12-18T16:33:21.549195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Cloning GitHub repository**\n",
    "This repository contains all the code, which was tested on a local machine. Part of this code will be modified slightly later on to align to Kaggle's environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b646be65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:21.559161Z",
     "iopub.status.busy": "2025-12-18T16:33:21.558442Z",
     "iopub.status.idle": "2025-12-18T16:33:22.749975Z",
     "shell.execute_reply": "2025-12-18T16:33:22.748991Z"
    },
    "papermill": {
     "duration": 1.196826,
     "end_time": "2025-12-18T16:33:22.751704",
     "exception": false,
     "start_time": "2025-12-18T16:33:21.554878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kaggle-sci-image-forgery-seg'...\r\n",
      "remote: Enumerating objects: 74, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (74/74), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (50/50), done.\u001b[K\r\n",
      "remote: Total 74 (delta 29), reused 57 (delta 17), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (74/74), 3.50 MiB | 20.23 MiB/s, done.\r\n",
      "Resolving deltas: 100% (29/29), done.\r\n",
      "total 40\r\n",
      "drwxr-xr-x 6 root root 4096 Dec 18 16:33 .\r\n",
      "drwxr-xr-x 3 root root 4096 Dec 18 16:33 ..\r\n",
      "drwxr-xr-x 2 root root 4096 Dec 18 16:33 configs\r\n",
      "drwxr-xr-x 8 root root 4096 Dec 18 16:33 .git\r\n",
      "-rw-r--r-- 1 root root  242 Dec 18 16:33 .gitignore\r\n",
      "drwxr-xr-x 2 root root 4096 Dec 18 16:33 notebooks\r\n",
      "-rw-r--r-- 1 root root 5480 Dec 18 16:33 README.md\r\n",
      "-rw-r--r-- 1 root root  368 Dec 18 16:33 requirements.txt\r\n",
      "drwxr-xr-x 2 root root 4096 Dec 18 16:33 src\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working\n",
    "!git clone https://github.com/jonny0349/kaggle-sci-image-forgery-seg\n",
    "!ls -la kaggle-sci-image-forgery-seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84f739",
   "metadata": {
    "papermill": {
     "duration": 0.003136,
     "end_time": "2025-12-18T16:33:22.758074",
     "exception": false,
     "start_time": "2025-12-18T16:33:22.754938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Installation of dependencies**\n",
    "\n",
    "We need some dependencies to be able to run the code in here, however, there was a conflict before with requirements.txt so we made sure to avoid installing TensorBoard/TensorFlow to avoid issues. We will install only what we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb18872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:22.765787Z",
     "iopub.status.busy": "2025-12-18T16:33:22.765389Z",
     "iopub.status.idle": "2025-12-18T16:33:29.471653Z",
     "shell.execute_reply": "2025-12-18T16:33:29.470836Z"
    },
    "papermill": {
     "duration": 6.712,
     "end_time": "2025-12-18T16:33:29.473346",
     "exception": false,
     "start_time": "2025-12-18T16:33:22.761346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\r\n",
      "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\r\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\r\n",
      "Collecting timm\r\n",
      "  Downloading timm-1.0.22-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting ruamel.yaml\r\n",
      "  Downloading ruamel_yaml-0.18.17-py3-none-any.whl.metadata (27 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.0.2)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (11.3.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.6.2)\r\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.23.0+cu126)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (4.67.1)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.15.3)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\r\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.12.5)\r\n",
      "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.1)\r\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\r\n",
      "Collecting ruamel.yaml.clib>=0.2.15 (from ruamel.yaml)\r\n",
      "  Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.1rc0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.11.12)\r\n",
      "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-1.0.22-py3-none-any.whl (2.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ruamel_yaml-0.18.17-py3-none-any.whl (121 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m354.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m414.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, timm, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.20\r\n",
      "    Uninstalling timm-1.0.20:\r\n",
      "      Successfully uninstalled timm-1.0.20\r\n",
      "Successfully installed ruamel.yaml-0.18.17 ruamel.yaml.clib-0.2.15 segmentation-models-pytorch-0.5.0 timm-1.0.22\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --no-cache-dir \\\n",
    "    segmentation-models-pytorch \\\n",
    "    albumentations \\\n",
    "    timm \\\n",
    "    ruamel.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264e309",
   "metadata": {
    "papermill": {
     "duration": 0.003972,
     "end_time": "2025-12-18T16:33:29.481422",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.477450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Patching train.py to disable TensorBoard safely**\n",
    "\n",
    "This is done to avoid issues with TensorBoard/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831ad76e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:29.490446Z",
     "iopub.status.busy": "2025-12-18T16:33:29.489863Z",
     "iopub.status.idle": "2025-12-18T16:33:29.496649Z",
     "shell.execute_reply": "2025-12-18T16:33:29.495910Z"
    },
    "papermill": {
     "duration": 0.013129,
     "end_time": "2025-12-18T16:33:29.498113",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.484984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled TensorBoard writer in train.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/train.py\")\n",
    "s= p.read_text()\n",
    "\n",
    "# 1. Remove/guard SummaryWriter import\n",
    "s = re.sub(r\"from torch\\.utils\\.tensorboard import SummaryWriter.*\\n\", \"SummaryWriter = None # disabled on Kaggle\\n\", s)\n",
    "\n",
    "# 2. Replace writer initialization with writer=None\n",
    "s = re.sub(r\"writer\\s*=\\s*SummaryWriter\\([^\\)]*\\)\\s*\", \"writer = None\\n\", s)\n",
    "\n",
    "# 3. Guard writer.close()\n",
    "s = s.replace(\"writer.close()\", \"if writer is not None:\\n  writer.close()\")\n",
    "\n",
    "p.write_text(s)\n",
    "print(\"Disabled TensorBoard writer in train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a45fa",
   "metadata": {
    "papermill": {
     "duration": 0.003654,
     "end_time": "2025-12-18T16:33:29.505893",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.502239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Patching data.py**\n",
    "\n",
    "This is done so the algorithm can layout nested images in folders such as `train_images/authentic/...` since it wasn't happening before due to paths being different in Kaggle than in local environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21022000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:29.514493Z",
     "iopub.status.busy": "2025-12-18T16:33:29.514111Z",
     "iopub.status.idle": "2025-12-18T16:33:29.524629Z",
     "shell.execute_reply": "2025-12-18T16:33:29.523965Z"
    },
    "papermill": {
     "duration": 0.016426,
     "end_time": "2025-12-18T16:33:29.526103",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.509677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched _collect_ids() for nested images + flat masks\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/data.py\")\n",
    "lines = p.read_text().splitlines()\n",
    "\n",
    "# Find start/end or _collect_ids\n",
    "start = None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.lstrip().startswith(\"def _collect_ids(\"):\n",
    "        start = i\n",
    "        break\n",
    "if start is None:\n",
    "    raise RuntimeError(\"Could not find def _collect_ids\")\n",
    "\n",
    "base_indent = len(lines[start]) - len(lines[start].lstrip())\n",
    "end = None\n",
    "for j in range(start + 1, len(lines)):\n",
    "    l = lines[j]\n",
    "    if not l.strip():\n",
    "        continue\n",
    "    indent_len = len(l) - len(l.lstrip())\n",
    "    if indent_len <= base_indent and (l.lstrip().startswith(\"def \") or l.lstrip().startswith(\"class \")):\n",
    "        end = j\n",
    "        break\n",
    "if end is None:\n",
    "    end = len(lines)\n",
    "\n",
    "indent = \" \" * base_indent\n",
    "\n",
    "new_fn = [\n",
    "f\"{indent}def _collect_ids(self) -> list[str]:\",\n",
    "f\"{indent}    \\\"\\\"\\\"Collect matching (image, mask) pairs for Kaggle layout.\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    Images are nested (authentic/forged). Masks are flat .npy files.\",\n",
    "f\"{indent}    \\\"\\\"\\\"\",\n",
    "f\"{indent}    import os\",\n",
    "f\"{indent}    from glob import glob\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    img_dir = self.images_dir\",\n",
    "f\"{indent}    msk_dir = self.masks_dir\",\n",
    "f\"{indent}    if not os.path.isdir(img_dir):\",\n",
    "f\"{indent}        raise RuntimeError(f\\\"Images directory not found: {{img_dir}}\\\")\",\n",
    "f\"{indent}    if not os.path.isdir(msk_dir):\",\n",
    "f\"{indent}        raise RuntimeError(f\\\"Masks directory not found: {{msk_dir}}\\\")\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    exts = ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp')\",\n",
    "f\"{indent}    img_paths = []\",\n",
    "f\"{indent}    for ext in exts:\",\n",
    "f\"{indent}        img_paths.extend(glob(os.path.join(img_dir, '**', f'*{{ext}}'), recursive=True))\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    stem_to_img = {{}}\",\n",
    "f\"{indent}    for ip in sorted(img_paths):\",\n",
    "f\"{indent}        stem = os.path.splitext(os.path.basename(ip))[0]\",\n",
    "f\"{indent}        stem_to_img.setdefault(stem, ip)\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    mask_paths = glob(os.path.join(msk_dir, '*.npy'))\",\n",
    "f\"{indent}    stem_to_msk = {{os.path.splitext(os.path.basename(mp))[0]: mp for mp in mask_paths}}\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    ids = sorted(set(stem_to_img.keys()) & set(stem_to_msk.keys()))\",\n",
    "f\"{indent}    if len(ids) == 0:\",\n",
    "f\"{indent}        raise RuntimeError(\",\n",
    "f\"{indent}            f\\\"No (image, mask) pairs found under {{img_dir}} and {{msk_dir}}.\\\\n\\\"\",\n",
    "f\"{indent}            f\\\"Found images: {{len(stem_to_img)}} (sample={{list(stem_to_img)[:10]}})\\\\n\\\"\",\n",
    "f\"{indent}            f\\\"Found masks : {{len(stem_to_msk)}} (sample={{list(stem_to_msk)[:10]}})\\\\n\\\"\",\n",
    "f\"{indent}            f\\\"Expected matching stems between images and masks.\\\"\",\n",
    "f\"{indent}        )\",\n",
    "f\"{indent}\",\n",
    "f\"{indent}    self._stem_to_img = stem_to_img\",\n",
    "f\"{indent}    self._stem_to_msk = stem_to_msk\",\n",
    "f\"{indent}    return ids\"\n",
    "]\n",
    "\n",
    "lines = lines[:start] + new_fn + lines[end:]\n",
    "p.write_text(\"\\n\".join(lines) + \"\\n\")\n",
    "print(\"Patched _collect_ids() for nested images + flat masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d355a",
   "metadata": {
    "papermill": {
     "duration": 0.003869,
     "end_time": "2025-12-18T16:33:29.534081",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.530212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we need to correct img_path right before cv2.imread to prevent overwrites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb80bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:29.543285Z",
     "iopub.status.busy": "2025-12-18T16:33:29.542890Z",
     "iopub.status.idle": "2025-12-18T16:33:29.549630Z",
     "shell.execute_reply": "2025-12-18T16:33:29.548782Z"
    },
    "papermill": {
     "duration": 0.01295,
     "end_time": "2025-12-18T16:33:29.551054",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.538104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected forced img_path resolution before cv2.imread\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg/src/data.py\")\n",
    "lines = p.read_text().splitlines()\n",
    "\n",
    "target_idx = None\n",
    "for i, line in enumerate(lines):\n",
    "    if \"cv2.imread\" in line:\n",
    "        target_idx = i\n",
    "        break\n",
    "if target_idx is None:\n",
    "    raise RuntimeError(\"Could not find cv2.imread in data.py\")\n",
    "\n",
    "indent = \" \" * (len(lines[target_idx]) - len(lines[target_idx].lstrip()))\n",
    "inject = [\n",
    "    f\"{indent}# --- Kaggle nested layout support (force correct path right before read) ---\",\n",
    "    f\"{indent}stem = self.ids[idx]\",\n",
    "    f\"{indent}img_path = getattr(self, '_stem_to_img', {{}}).get(stem)\",\n",
    "    f\"{indent}if img_path is None:\",\n",
    "    f\"{indent}    from glob import glob\",\n",
    "    f\"{indent}    cands = glob(os.path.join(self.images_dir, '**', f'{{stem}}.*'), recursive=True)\",\n",
    "    f\"{indent}    img_path = cands[0] if cands else os.path.join(self.images_dir, f'{{stem}}.png')\",\n",
    "]\n",
    "\n",
    "lines = lines[:target_idx] + inject + lines[target_idx:]\n",
    "p.write_text(\"\\n\".join(lines) + \"\\n\")\n",
    "print(\"Injected forced img_path resolution before cv2.imread\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85baa615",
   "metadata": {
    "papermill": {
     "duration": 0.004167,
     "end_time": "2025-12-18T16:33:29.559173",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.555006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "** Creating configs**\n",
    "\n",
    "We need to modify the configs/baseline.yaml to make sure we have the correct paths for Kaggle. First, we need to make a copy of the baseline.yaml and name it kaggle.yaml, then we will make the edits to adjust to the correct paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d09cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:29.570094Z",
     "iopub.status.busy": "2025-12-18T16:33:29.569389Z",
     "iopub.status.idle": "2025-12-18T16:33:29.601986Z",
     "shell.execute_reply": "2025-12-18T16:33:29.601038Z"
    },
    "papermill": {
     "duration": 0.040168,
     "end_time": "2025-12-18T16:33:29.603663",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.563495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /kaggle/working/kaggle-sci-image-forgery-seg/configs/kaggle.yaml\n",
      "['project:', '  seed: 2025', '  device: cuda', '  output_dir: outputs', 'data:', '  root: /kaggle/input/recodai-luc-scientific-image-forgery-detection', '  train_images_dir: /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images', '  train_masks_dir: /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_masks', '  val_images_dir: /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images', '  val_masks_dir: /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_masks', '  img_ext: .png', '  mask_ext: .npy', \"  mask_suffix: ''\", '  num_classes: 1', '  background_is_zero: true', 'augment:', '  train:', '    resize:', '    - 768', '    - 768', '    hflip_p: 0.5', '    vflip_p: 0.0', '    rotate_limit: 10', '    rotate_p: 0.25', '    brightness_contrast_p: 0.15', '  val:', '    resize:', '    - 768', '    - 768', 'model:']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "base = Path(\"/kaggle/working/kaggle-sci-image-forgery-seg\")\n",
    "src_cfg = base / \"configs\" / \"baseline.yaml\"\n",
    "dst_cfg = base / \"configs\" / \"kaggle.yaml\"\n",
    "\n",
    "cfg = yaml.safe_load(src_cfg.read_text())\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection\"\n",
    "OUT_ROOT = str(base / \"outputs\")\n",
    "\n",
    "cfg.setdefault(\"data\", {})\n",
    "cfg[\"data\"][\"root\"] = DATA_ROOT\n",
    "cfg[\"outputs\"] = cfg.get(\"outputs\", {})\n",
    "cfg[\"outputs\"][\"root\"] = OUT_ROOT\n",
    "\n",
    "# Important: point to Kaggle's actual folder names\n",
    "cfg[\"data\"][\"train_images_dir\"] = f\"{DATA_ROOT}/train_images\"\n",
    "cfg[\"data\"][\"train_masks_dir\"] = f\"{DATA_ROOT}/train_masks\"\n",
    "cfg[\"data\"][\"val_images_dir\"] = f\"{DATA_ROOT}/train_images\" #Temporary until we make a true split\n",
    "cfg[\"data\"][\"val_masks_dir\"] = f\"{DATA_ROOT}/train_masks\"\n",
    "\n",
    "# GPU settings\n",
    "cfg.setdefault(\"project\", {})\n",
    "cfg[\"project\"][\"device\"] = \"cuda\"\n",
    "\n",
    "dst_cfg.write_text(yaml.safe_dump(cfg, sort_keys=False))\n",
    "print(\"Wrote\", dst_cfg)\n",
    "print(dst_cfg.read_text().splitlines()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8302bb5",
   "metadata": {
    "papermill": {
     "duration": 0.004008,
     "end_time": "2025-12-18T16:33:29.611566",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.607558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Running Training**\n",
    "\n",
    "Now we are ready to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332e1d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:29.620689Z",
     "iopub.status.busy": "2025-12-18T16:33:29.620202Z",
     "iopub.status.idle": "2025-12-18T16:33:29.838664Z",
     "shell.execute_reply": "2025-12-18T16:33:29.837588Z"
    },
    "papermill": {
     "duration": 0.225327,
     "end_time": "2025-12-18T16:33:29.840597",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.615270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 159, in _get_module_details\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1133, in get_code\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1063, in source_to_code\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n",
      "  File \"/kaggle/working/kaggle-sci-image-forgery-seg/src/train.py\", line 126\r\n",
      "    save_json(cfg.to_dict(), os.path.join(out_dir, \"config_snapshot.json\"))\r\n",
      "IndentationError: unexpected indent\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/kaggle-sci-image-forgery-seg && python -m src.train --cfg configs/kaggle.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97ad37",
   "metadata": {
    "papermill": {
     "duration": 0.004145,
     "end_time": "2025-12-18T16:33:29.849135",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.844990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Run Inference**\n",
    "\n",
    "We run inference just for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d6e8a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:29.859207Z",
     "iopub.status.busy": "2025-12-18T16:33:29.858511Z",
     "iopub.status.idle": "2025-12-18T16:33:45.223202Z",
     "shell.execute_reply": "2025-12-18T16:33:45.222471Z"
    },
    "papermill": {
     "duration": 15.37168,
     "end_time": "2025-12-18T16:33:45.224928",
     "exception": false,
     "start_time": "2025-12-18T16:33:29.853248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "CWD: /kaggle/working/kaggle-sci-image-forgery-seg\r\n",
      "Input dir: /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/forged\r\n",
      "Output dir: /kaggle/working/outputs/preds/forged_demo\r\n",
      "Checkpoint: /kaggle/working/kaggle-sci-image-forgery-seg/outputs/checkpoints/best_dice.pt\r\n",
      "config.json: 100%|█████████████████████████████| 156/156 [00:00<00:00, 1.02MB/s]\r\n",
      "model.safetensors: 100%|███████████████████| 87.3M/87.3M [00:01<00:00, 76.0MB/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/kaggle/working/kaggle-sci-image-forgery-seg/src/infer.py\", line 166, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/kaggle-sci-image-forgery-seg/src/infer.py\", line 109, in main\r\n",
      "    ckpt = torch.load(args.checkpoint, map_location=\"cpu\")\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1484, in load\r\n",
      "    with _open_file_like(f, \"rb\") as opened_file:\r\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 759, in _open_file_like\r\n",
      "    return _open_file(name_or_buffer, mode)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 740, in __init__\r\n",
      "    super().__init__(open(name, mode))\r\n",
      "                     ^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/kaggle-sci-image-forgery-seg/outputs/checkpoints/best_dice.pt'\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/kaggle-sci-image-forgery-seg && python -m src.infer \\\n",
    "  --cfg configs/kaggle.yaml \\\n",
    "  --checkpoint /kaggle/working/kaggle-sci-image-forgery-seg/outputs/checkpoints/best_dice.pt \\\n",
    "  --input_dir /kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/forged \\\n",
    "  --output_dir /kaggle/working/outputs/preds/forged_demo \\\n",
    "  --thr 0.5 \\\n",
    "  --save_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df9096b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:45.236868Z",
     "iopub.status.busy": "2025-12-18T16:33:45.236293Z",
     "iopub.status.idle": "2025-12-18T16:33:45.360997Z",
     "shell.execute_reply": "2025-12-18T16:33:45.360120Z"
    },
    "papermill": {
     "duration": 0.133048,
     "end_time": "2025-12-18T16:33:45.362943",
     "exception": false,
     "start_time": "2025-12-18T16:33:45.229895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/working/kaggle-sci-image-forgery-seg/outputs/checkpoints/best_dice.pt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/working/kaggle-sci-image-forgery-seg/outputs/checkpoints/best_dice.pt /kaggle/working/best_dice.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939ef3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T16:33:45.376348Z",
     "iopub.status.busy": "2025-12-18T16:33:45.375663Z",
     "iopub.status.idle": "2025-12-18T16:33:45.508838Z",
     "shell.execute_reply": "2025-12-18T16:33:45.507876Z"
    },
    "papermill": {
     "duration": 0.142339,
     "end_time": "2025-12-18T16:33:45.510699",
     "exception": false,
     "start_time": "2025-12-18T16:33:45.368360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: outputs/checkpoints\r\n",
      "\tzip warning: name not matched: outputs/logs\r\n",
      "\tzip warning: name not matched: outputs/preds\r\n",
      "\tzip warning: name not matched: outputs/config_snapshot.json\r\n",
      "\r\n",
      "zip error: Nothing to do! (try: zip -r /kaggle/working/artifacts.zip . -i outputs/checkpoints outputs/logs outputs/preds outputs/config_snapshot.json)\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/kaggle-sci-image-forgery-seg && \\\n",
    "    zip -r /kaggle/working/artifacts.zip outputs/checkpoints outputs/logs outputs/preds outputs/config_snapshot.json"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14878066,
     "sourceId": 113558,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31240,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.922973,
   "end_time": "2025-12-18T16:33:46.234392",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-18T16:33:15.311419",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
